version: "3.9"
services:
  tei:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.6
    container_name: tei
    ports:
      - "8080:80"
    volumes:
      - ./hf_cache:/data
    command:
      [
        "--model-id", "BAAI/bge-m3",
        # "--pooling", "cls",
        "--max-client-batch-size", "512",
        "--payload-limit", "15728640",
        "--auto-truncate"
      ]
    restart: always
  nginx:
    image: nginx:alpine
    container_name: tei-nginx
    ports:
      - "8081:8081"  # 外部访问用这个端口
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - tei
    restart: always
networks:
  default:
    driver: bridge
